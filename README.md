# ğŸ§© æ–‡æœ¬å†²çªæ•°æ®é›†

## ğŸ“˜ æ•°æ®æ ¼å¼

æ¯æ¡æ ·æœ¬ä¸ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ•°æ®é›†æ•´ä½“ä¸ºä¸€ä¸ª JSON æ•°ç»„ã€‚

```json
[
    {
        "category": 3,
        "original_statement": {
            "statement": "",
            "chunk": 1,
            "position": 3
        },
        "conflicting_statement": {
            "statement": "",
            "chunk": 2,
            "position": 7
        },
        "chunk_distance": 1,
        "similarity": 0.3,
        "contradiction_level": 1,
        "source": "auto"
    }
]
```

---

## ğŸ§± å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | ç¤ºä¾‹ | è¯´æ˜ |
|------|------|------|------|
| `category` | `int` | `3` | å†²çªç±»å‹ç¼–å·ï¼ˆè§ä¸‹æ–¹åˆ†ç±»è¡¨ï¼‰ã€‚ |
| `original_statement` | `object` | `{ "statement": "æœ¯åéœ€è¦ä¼‘æ¯åå¤©", "chunk": 1, "position": 3 }` | åŸå§‹å¥æˆ–æ®µè½ã€‚ |
| â”— `statement` | `string` | `"æœ¯åéœ€è¦ä¼‘æ¯åå¤©"` | åŸå§‹ä¿¡æ¯æ–‡æœ¬ã€‚ |
| â”— `chunk` | `int` | `1` | æ‰€åœ¨æ–‡æœ¬å—ç¼–å·ã€‚ |
| â”— `position` | `int` | `3` | æ–‡æœ¬ä½ç½®ï¼ˆå¥å·ç¼–å·ã€å­—ç¬¦ç´¢å¼•ç­‰ï¼‰ã€‚ |
| `conflicting_statement` | `object` | `{ "statement": "æœ¯åéœ€è¦ç«‹å³è¿åŠ¨", "chunk": 2, "position": 7 }` | ä¸åŸæ–‡çŸ›ç›¾çš„å¥å­ã€‚ |
| `chunk_distance` | `int` | `2` | ä¸¤ä¸ªå†²çªå¥æ‰€åœ¨ chunk çš„è·ç¦»ã€‚ |
| `similarity` | `float` | `0.3` | è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆ0~1ï¼‰ã€‚ |
| `contradiction_level` | `int` | `0` | å†²çªå±‚çº§ï¼š`0`=éšæ€§ï¼›`1`=æ˜¾æ€§ã€‚ |
| `source` | `string` | `"auto"` | æ ·æœ¬æ¥æºï¼š`"auto"`ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰æˆ– `"manual"`ï¼ˆäººå·¥æ ‡æ³¨ï¼‰ã€‚ |

## ğŸ§  contradiction_level è¯´æ˜

| å€¼ | ç±»å‹ | å®šä¹‰ | ç¤ºä¾‹ |
|----|------|------|------|
| **0** | **éšæ€§å†²çªï¼ˆImplicitï¼‰** | è¯­ä¹‰æˆ–é€»è¾‘å±‚çŸ›ç›¾ï¼Œéœ€è¦å¸¸è¯†æˆ–ä¸Šä¸‹æ–‡ç†è§£ã€‚ | â€œæœ¯ååº”é¿å…è¿åŠ¨â€ â†” â€œåŒ»ç”Ÿå»ºè®®æœ¯åè¿›è¡Œåº·å¤è®­ç»ƒâ€ã€‚ |
| **1** | **æ˜¾æ€§å†²çªï¼ˆExplicitï¼‰** | å­—é¢è¯­ä¹‰ç›´æ¥å¯¹ç«‹ï¼Œæ— éœ€æ¨ç†ã€‚ | â€œç¦æ­¢å¸çƒŸâ€ â†” â€œå¯ä»¥å¸çƒŸâ€ã€‚ |

---

## ğŸ“š å†²çªç±»å‹åˆ†ç±»è¡¨ï¼ˆcategoryï¼‰

| ID | å†²çªç±»å‹ | å®šä¹‰ | ç¤ºä¾‹ |
|----|------------|------|------|
| **1** | **æ•°å€¼å†²çªï¼ˆNumerical Conflictï¼‰** | å¯¹åŒä¸€äº‹å®ã€æ•°é‡ã€æ—¶é—´æˆ–èŒƒå›´çš„æè¿°ä¸ä¸€è‡´ã€‚ | â€œè¡€å‹åœ¨60â€“100ä¹‹é—´ä¸ºæ­£å¸¸â€ â†” â€œè¡€å‹åœ¨80â€“120ä¹‹é—´ä¸ºæ­£å¸¸â€ï¼›â€œæ¯å¤©æœè¯ä¸¤æ¬¡â€ â†” â€œæ¯å¤©æœè¯ä¸€æ¬¡â€ã€‚ |
| **2** | **è¯­ä¹‰å†²çªï¼ˆSemantic Conflictï¼‰** | å¯¹åŒä¸€è¡Œä¸ºæˆ–å»ºè®®è¡¨è¾¾ç›¸åçš„è¯­ä¹‰ã€‚ | â€œæœ¯åéœ€è¦ä¼‘æ¯åå¤©â€ â†” â€œæœ¯åéœ€è¦ç«‹å³è¿åŠ¨â€ï¼›â€œç¦æ­¢é¥®é…’â€ â†” â€œå»ºè®®æ¯å¤©å°‘é‡é¥®é…’â€ã€‚ |
| **3** | **é€»è¾‘å†²çªï¼ˆLogical Conflictï¼‰** | å› æœã€æ¡ä»¶æˆ–æ¨ç†æ–¹å‘äº’ç›¸çŸ›ç›¾ã€‚ | â€œå¦‚æœæ‘„å…¥è¿‡å¤šç³–ï¼Œå¯èƒ½å¾—ç³–å°¿ç—…â€ â†” â€œå¾—äº†ç³–å°¿ç—…ä¸€å®šæ˜¯å› ä¸ºæ‘„å…¥ç³–è¿‡å¤šâ€ï¼›â€œå› ä¸ºåƒè¯ä»–åº·å¤äº†â€ â†” â€œå› ä¸ºåƒè¯ä»–ç”Ÿç—…äº†â€ã€‚ |



---

## ğŸ§ª ç¤ºä¾‹æ ·æœ¬

```json
[
    {
        "category": 2,
        "original_statement": {
            "statement": "æœ¯åéœ€è¦ä¼‘æ¯åå¤©ã€‚",
            "chunk": 1,
            "position": 3
        },
        "conflicting_statement": {
            "statement": "æœ¯åéœ€è¦ç«‹å³è¿åŠ¨ã€‚",
            "chunk": 2,
            "position": 7
        },
        "chunk_distance": 2,
        "similarity": 0.38,
        "contradiction_level": 0,
        "source": "auto"
    }
]
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install openai sentence-transformers numpy

# é…ç½®APIå¯†é’¥
# åœ¨ ../config/config.cfg ä¸­è®¾ç½® ali_api_key
```

### 2. æ•°æ®é›†æ„å»º

#### 2.1 å‡†å¤‡æºæ–‡æ¡£
å°†é•¿æ–‡æœ¬æ–‡æ¡£æ”¾ç½®åœ¨ `dataset/data.txt`

#### 2.2 è¿è¡Œè‡ªåŠ¨æ„å»º
```bash
cd error_detect
python data_construct.py
```

**ç”Ÿæˆæ–‡ä»¶:**
- `dataset/chunks.json` - æ–‡æ¡£åˆ†å—ç»“æœ(åŒ…å«åŸå§‹æ–‡æœ¬å’Œæ’å…¥å†²çªåçš„æ–‡æœ¬)
- `dataset/error_data1.json` - å†²çªæ•°æ®é›†
- `dataset/error_data1_stats.json` - ç»Ÿè®¡ä¿¡æ¯
- `logs/data_construct_*.log` - è¯¦ç»†è¿è¡Œæ—¥å¿—

#### 2.3 æ›´æ–°ä½ç½®ä¿¡æ¯(å¯é€‰)
```bash
python update_positions.py
```

è‡ªåŠ¨å®šä½é™ˆè¿°åœ¨chunkä¸­çš„ç²¾ç¡®å¥å­ä½ç½®,æ”¯æŒ4çº§åŒ¹é…ç­–ç•¥(ç²¾ç¡®â†’åŒ…å«â†’è§„èŒƒåŒ–â†’æ¨¡ç³Š)ã€‚

---

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
error_detect/
â”œâ”€â”€ data_construct.py       # ä¸»æ„å»ºè„šæœ¬(LLMè‡ªåŠ¨ç”Ÿæˆå†²çªæ•°æ®é›†)
â”œâ”€â”€ prompts.py              # æç¤ºè¯æ¨¡æ¿åº“(æå–é™ˆè¿°+ç”Ÿæˆå†²çª)
â”œâ”€â”€ update_positions.py     # ä½ç½®æ›´æ–°å·¥å…·(ç²¾ç¡®å®šä½å¥å­ä½ç½®)
â”œâ”€â”€ README.md               # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ data.txt           # æºæ–‡æ¡£(é•¿æ–‡æœ¬)
â”‚   â”œâ”€â”€ chunks.json        # åˆ†å—ç»“æœ(original_text + processed_text)
â”‚   â”œâ”€â”€ error_data1.json   # å†²çªæ•°æ®é›†
â”‚   â””â”€â”€ error_data1_stats.json  # ç»Ÿè®¡ä¿¡æ¯
â””â”€â”€ logs/
    â””â”€â”€ data_construct_*.log    # è¿è¡Œæ—¥å¿—(å«LLMå¯¹è¯è¯¦æƒ…)
```

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. æ–‡æ¡£åˆ†å— (`load_and_chunk_document`)
- æŒ‰å¥å­è¾¹ç•Œåˆ†å‰²,ä¸åˆ‡æ–­å¥å­
- é»˜è®¤åˆ†æˆ10ä¸ªchunk
- ä¿ç•™åŸå§‹æ–‡æœ¬(`original_text`)å’Œå¤„ç†æ–‡æœ¬(`processed_text`)

### 2. é™ˆè¿°æå– (`extract_key_statements`)
- ä½¿ç”¨Qwen-Maxä»æ¯ä¸ªchunkæå–å…³é”®é™ˆè¿°
- ä¼˜å…ˆæå–åŒ…å«æ•°å€¼ã€é¢‘ç‡ã€æ—¶é—´çš„é™ˆè¿°
- ç¡®ä¿é€å­—é€å¥ä»åŸæ–‡æå–(temperature=0.1)

### 3. å†²çªç”Ÿæˆ (`generate_conflicting_statement`)
- ä¸‰ç§å†²çªç±»å‹,å„æœ‰ä¸“å±æç¤ºè¯:
  - **ç±»å‹1**: æ•°å€¼å†²çª(æ”¹å˜æ•°å€¼/èŒƒå›´/é¢‘ç‡/æ—¶é—´)
  - **ç±»å‹2**: è¯­ä¹‰å†²çª(è¡¨è¾¾ç›¸åå»ºè®®æˆ–è¡Œä¸º)
  - **ç±»å‹3**: é€»è¾‘å†²çª(æ”¹å˜å› æœ/æ¡ä»¶å…³ç³»)
- ä½¿ç”¨åŒä¹‰æ›¿æ¢å’Œå¥å¼é‡ç»„,é¿å…ç®€å•å¦å®š
- ä¿æŒä¸“ä¸šæ€§å’Œè‡ªç„¶æ€§

### 4. ç›¸ä¼¼åº¦è®¡ç®— (`calculate_cosine_similarity`)
- ä½¿ç”¨sentence-transformersè®¡ç®—å®é™…ä½™å¼¦ç›¸ä¼¼åº¦
- æ¨¡å‹: `all-MiniLM-L6-v2`
- ç¡®ä¿å†²çªé™ˆè¿°ä¸åŸé™ˆè¿°æœ‰è¶³å¤Ÿå·®å¼‚

### 5. ä½ç½®å®šä½ (`find_sentence_position`)
**4çº§åŒ¹é…ç­–ç•¥:**
1. **ç²¾ç¡®åŒ¹é…**: å­—ç¬¦ä¸²å®Œå…¨ç›¸ç­‰
2. **åŒ…å«åŒ¹é…**: é™ˆè¿°ä¸å¥å­äº’ç›¸åŒ…å«
3. **è§„èŒƒåŒ–åŒ¹é…**: å»é™¤æ ‡ç‚¹å’Œç©ºæ ¼åæ¯”å¯¹
4. **æ¨¡ç³ŠåŒ¹é…**: åŸºäºå­—ç¬¦é‡å ç‡(é˜ˆå€¼80%)

### 6. æ—¥å¿—è®°å½•
æ‰€æœ‰è¿è¡Œæµç¨‹ã€LLMæç¤ºè¯ã€è¿”å›å†…å®¹å‡è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶:
- ç³»ç»Ÿ/ç”¨æˆ·æç¤ºè¯å®Œæ•´å†…å®¹
- APIè¯·æ±‚å‚æ•°(model, temperature, max_tokens)
- LLMè¿”å›çš„åŸå§‹å“åº”
- è§£æç»“æœå’Œç»Ÿè®¡ä¿¡æ¯

---

## âš™ï¸ é…ç½®å‚æ•°

åœ¨ `data_construct.py` çš„ `main()` å‡½æ•°ä¸­ä¿®æ”¹:

```python
# æ–‡ä»¶è·¯å¾„
input_file = "dataset/data.txt"
chunks_file = "dataset/chunks.json"
output_file = "dataset/error_data1.json"

# æ„å»ºå‚æ•°
num_chunks = 10              # åˆ†å—æ•°é‡
num_conflicts = 1            # ç”Ÿæˆå†²çªå¯¹æ•°é‡
min_chunk_distance = 3       # æœ€å°å—è·ç¦»(å†²çªé™ˆè¿°å¿…é¡»åœ¨åŸé™ˆè¿°ä¹‹å)
```

---

## ğŸ“Š æ•°æ®é›†ç»Ÿè®¡

è¿è¡Œåè‡ªåŠ¨ç”Ÿæˆ `error_data1_stats.json`:

```json
{
    "total_conflicts": 10,
    "category_distribution": {
        "1": 3,
        "2": 4,
        "3": 3
    },
    "contradiction_level_distribution": {
        "0": 6,
        "1": 4
    },
    "avg_chunk_distance": 4.2,
    "avg_similarity": 0.35,
    "source_distribution": {
        "auto": 10
    }
}
```

---

## ğŸ¯ è®¾è®¡åŸåˆ™

### 1. ä¸¤é˜¶æ®µæµç¨‹
- **é˜¶æ®µ1**: ä»åŸå§‹æ–‡æœ¬æå–å…³é”®é™ˆè¿°
- **é˜¶æ®µ2**: åŸºäºé™ˆè¿°ç”Ÿæˆå†²çª,æ’å…¥åˆ°åç»­chunk

### 2. ä½ç½®çº¦æŸ
- å†²çªé™ˆè¿°å¿…é¡»å‡ºç°åœ¨åŸé™ˆè¿°**ä¹‹å**çš„chunk
- é»˜è®¤æœ€å°è·ç¦»3ä¸ªchunk(å¯é…ç½®)
- å¦‚æ— æ³•æ»¡è¶³,åˆ™é€‰æ‹©ä»»æ„åç»­chunk

### 3. è´¨é‡ä¿è¯
- æå–æ—¶ä½¿ç”¨ä½æ¸©åº¦(0.1)ç¡®ä¿å‡†ç¡®
- ç”Ÿæˆæ—¶ä½¿ç”¨ä¸­æ¸©åº¦(0.7)ä¿æŒåˆ›æ„
- è®¡ç®—å®é™…ä½™å¼¦ç›¸ä¼¼åº¦
- 4çº§åŒ¹é…ç­–ç•¥ç¡®ä¿ä½ç½®å‡†ç¡®

### 4. å¯è¿½æº¯æ€§
- è¯¦ç»†æ—¥å¿—è®°å½•æ‰€æœ‰LLMäº¤äº’
- ä¿ç•™åŸå§‹æ–‡æœ¬å’Œå¤„ç†æ–‡æœ¬
- è®°å½•æ¯ä¸ªå†²çªå¯¹çš„æ¥æºå’Œå‚æ•°

---
## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ‘¥ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ”¹è¿›æ•°æ®é›†è´¨é‡!

